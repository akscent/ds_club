{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/akscent/feature-extraction-classifer-txt?scriptVersionId=149943051\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"\n!pip install pymorphy2 cleantext -U pip setuptools wheel nlp_profiler textblob pymystem3 > installer_log.txt\n!pip install spacy > installer_log.txt\nimport os\nimport sys\nimport torch\nimport json\nimport spacy\nimport io\nimport ru_core_news_md\nimport shap\nshap.initjs()\nimport pandas as pd\nimport numpy as np\n\nfrom numpy import asarray\nfrom collections import Counter\nfrom typing import Dict\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam, AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer, AutoModel, MBartTokenizer, MBartForConditionalGeneration, BertTokenizer, BertForSequenceClassification\nfrom textblob import TextBlob\nfrom nlp_profiler.core import apply_text_profiling\nfrom pymystem3 import Mystem\nfrom nltk.corpus import stopwords\nfrom catboost import CatBoostClassifier\n\n# sys.path.insert(1, '/kaggle/input/ods-huawei/nlp_huawei_new2_task-master/nlp_huawei_new2_task-master/baseline_transformers')\n# from dataset import *\n# from model import *\n# from trainer import Trainer\n\ntorch.manual_seed(42)","metadata":{"collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FiveDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_seq_len):\n        self.data = dataframe\n        self.text = dataframe['text'].tolist()\n        self.targets = None\n        if 'rate' in dataframe:\n            self.targets = dataframe['rate'].tolist()\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __getitem__(self, index):\n        text = str(self.text[index])\n        text = ' '.join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_seq_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n\n        if self.targets is not None:\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n                'targets': torch.tensor(self.targets[index], dtype=torch.long)\n            }\n        else:\n            return {\n                'ids': torch.tensor(ids, dtype=torch.long),\n                'mask': torch.tensor(mask, dtype=torch.long),\n            }\n\n    def __len__(self) -> int:\n        return len(self.text)\n    \n\nclass ModelForClassification(torch.nn.Module):\n\n    def __init__(self, model_path: str, config: Dict):\n        super(ModelForClassification, self).__init__()\n        self.model_name = model_path\n        self.config = config\n        self.n_classes = config['num_classes']\n        self.dropout_rate = config['dropout_rate']\n        self.bert = AutoModel.from_pretrained(self.model_name)\n        self.pre_classifier = torch.nn.Linear(312, 768)\n        self.dropout = torch.nn.Dropout(self.dropout_rate)\n        self.classifier = torch.nn.Linear(768, self.n_classes)\n        self.softmax = torch.nn.LogSoftmax(dim = 1)\n\n    def forward(self, input_ids, attention_mask,):\n        output = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n        hidden_state = output[0]\n        hidden_state = hidden_state[:, 0]\n        hidden_state = self.pre_classifier(hidden_state)\n        hidden_state = torch.nn.ReLU()(hidden_state)\n        hidden_state = self.dropout(hidden_state)\n        output = self.classifier(hidden_state)\n        output = self.softmax(output)\n        return output\n\n\nclass Trainer:\n    def __init__(self, config: Dict, class_weights=None):\n        self.config = config\n        self.device = config['device']\n        self.n_epochs = config['n_epochs']\n        self.optimizer = None\n        self.opt_fn = lambda model: AdamW(model.parameters(), config['lr'])\n        self.model = None\n        self.history = None\n        if class_weights is not None:\n            class_weights = class_weights.to(self.device)\n            self.loss_fn = CrossEntropyLoss(weight=class_weights)\n        else:\n            self.loss_fn = CrossEntropyLoss()\n        self.device = config['device']\n        self.verbose = config.get('verbose', True)\n        \n    def save_history(self, path: str):\n        history = {\n            'train_loss': self.history['train_loss'],\n            'val_loss': self.history['val_loss'],\n            'val_acc': self.history['val_acc']\n        }\n        val_acc = sum(self.history['val_acc']) / len(self.history['val_acc'])\n        print(\"All ACCURACY = \", val_acc)\n        with open(path, 'w') as file:\n            json.dump(history, file)\n        \n    def load_history(self, path: str):\n        with open(path, 'r') as file:\n            history = json.load(file)\n        self.history = {\n            'train_loss': history['train_loss'],\n            'val_loss': history['val_loss'],\n            'val_acc': history['val_acc']\n        }\n\n    def fit(self, model, train_dataloader, val_dataloader):\n        self.model = model.to(self.device)\n        self.optimizer = self.opt_fn(model)\n        self.history = {\n            'train_loss': [],\n            'val_loss': [],\n            'val_acc': []\n        }\n        best_val_loss = float('inf')\n\n        for epoch in range(self.n_epochs):\n            print(f\"Epoch {epoch + 1}/{self.n_epochs}\")\n            train_info = self.train_epoch(train_dataloader)\n            val_info = self.val_epoch(val_dataloader)\n            self.history['train_loss'].extend(train_info['loss'])\n            self.history['val_loss'].extend([val_info['loss']])\n            self.history['val_acc'].extend([val_info['acc']])\n\n            if val_info['loss'] < best_val_loss:\n                best_val_loss = val_info['loss']\n                self.save_model_weights('best_model_weights.ckpt')\n\n            self.save_history('history.json')\n\n        return self.model.eval()\n\n    def save_model_weights(self, path: str):\n        torch.save(self.model.state_dict(), path)\n\n\n\n    def train_epoch(self, train_dataloader):\n        self.model.train()\n        losses = []\n        total_loss = 0\n        if self.verbose:\n            train_dataloader = tqdm(train_dataloader)\n        for batch in train_dataloader:\n            ids = batch['ids'].to(self.device, dtype=torch.long)\n            mask = batch['mask'].to(self.device, dtype=torch.long)\n            targets = batch['targets'].to(self.device, dtype=torch.long)\n\n            outputs = self.model(ids, mask)\n            loss = self.loss_fn(outputs, targets)\n            total_loss += loss.item()\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            loss_val = loss.item()\n            if self.verbose:\n                train_dataloader.set_description(f\"Loss={loss_val:.3}\")\n            losses.append(loss_val)\n        avg_loss = total_loss / len(train_dataloader)\n        print(\"AVG LOSS = \", avg_loss)\n        return {'loss': losses}\n\n    def val_epoch(self, val_dataloader):\n        self.model.eval()\n        all_logits = []\n        all_labels = []\n        if self.verbose:\n            val_dataloader = tqdm(val_dataloader)\n        with torch.no_grad():\n            for batch in val_dataloader:\n                ids = batch['ids'].to(self.device, dtype=torch.long)\n                mask = batch['mask'].to(self.device, dtype=torch.long)\n                targets = batch['targets'].to(self.device, dtype=torch.long)\n                outputs = self.model(ids, mask)\n                all_logits.append(outputs)\n                all_labels.append(targets)\n        all_labels = torch.cat(all_labels).to(self.device)\n        all_logits = torch.cat(all_logits).to(self.device)\n        loss = self.loss_fn(all_logits, all_labels).item()\n        acc = (all_logits.argmax(1) == all_labels).float().mean().item()\n        print(\"ACCURACY for EPOCH = \", acc)\n        if self.verbose:\n            val_dataloader.set_description(f\"Loss={loss:.3}; Acc:{acc:.3}\")\n        return {\n            'acc': acc,\n            'loss': loss\n        }\n\n    def predict(self, test_dataloader):\n        if not self.model:\n            raise RuntimeError(\"You should train the model first\")\n        self.model.eval()\n        predictions = []\n        with torch.no_grad():\n            for batch in test_dataloader:\n                ids = batch['ids'].to(self.device, dtype=torch.long)\n                mask = batch['mask'].to(self.device, dtype=torch.long)\n                outputs = self.model(ids, mask)\n                preds = torch.exp(outputs)\n                predictions.extend(preds.tolist())\n        return asarray(predictions)\n\n    def save(self, path: str):\n        if self.model is None:\n            raise RuntimeError(\"You should train the model first\")\n        checkpoint = {\n            \"config\": self.model.config,\n            \"trainer_config\": self.config,\n            \"model_name\": self.model.model_name,\n            \"model_state_dict\": self.model.state_dict()\n        }\n        torch.save(checkpoint, path)\n\n    def plot_history(self):\n        import matplotlib.pyplot as plt\n        \n        if self.history is None:\n            raise RuntimeError(\"History is not available. Train the model first.\")\n\n        train_loss = self.history['train_loss']\n        val_loss = self.history['val_loss']\n        val_acc = self.history['val_acc']\n\n        epochs = range(1, len(train_loss) + 1)\n\n        plt.figure(figsize=(12, 5))\n\n        plt.subplot(1, 2, 1)\n        plt.plot(epochs, train_loss, 'bo', label='Training loss')\n        plt.plot(epochs, val_loss, 'r', label='Validation loss')\n        plt.title('Training and Validation Loss')\n        plt.xlabel('Epochs')\n        plt.ylabel('Loss')\n        plt.legend()\n\n        plt.subplot(1, 2, 2)\n        plt.plot(epochs, val_acc, 'g', label='Validation accuracy')\n        plt.title('Validation Accuracy')\n        plt.xlabel('Epochs')\n        plt.ylabel('Accuracy')\n        plt.legend()\n\n        plt.show()\n\n\n    @classmethod\n    def load(cls, path: str):\n        ckpt = torch.load(path)\n        keys = [\"config\", \"trainer_config\", \"model_state_dict\"]\n        for key in keys:\n            if key not in ckpt:\n                raise RuntimeError(f\"Missing key {key} in checkpoint\")\n        new_model = ModelForClassification(\n            ckpt['model_name'],\n            ckpt[\"config\"]\n        )\n        new_model.load_state_dict(ckpt[\"model_state_dict\"])\n        new_trainer = cls(ckpt[\"trainer_config\"])\n        new_trainer.model = new_model\n        new_trainer.model.to(new_trainer.device)\n        return new_trainer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data load","metadata":{}},{"cell_type":"code","source":"PATH = \"/kaggle/input/ods-huawei/\"\ntrain_data = pd.read_csv(os.path.join(PATH, \"train.csv\"))\ntest_data = pd.read_csv(os.path.join(PATH, \"test.csv\"))\nle = LabelEncoder()\ntrain_data.rate = le.fit_transform(train_data.rate)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:19:43.033117Z","iopub.execute_input":"2023-11-05T06:19:43.03346Z","iopub.status.idle":"2023-11-05T06:19:43.594763Z","shell.execute_reply.started":"2023-11-05T06:19:43.033433Z","shell.execute_reply":"2023-11-05T06:19:43.593753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-clean text","metadata":{}},{"cell_type":"code","source":"# import re\n# TOKEN_RE = re.compile(r'[а-яё]+')\n\n# def tokenize_text(text, min_length_token=1):\n#     text = text.lower()\n#     tokens = TOKEN_RE.findall(text)\n#     return [token for token in tokens if len(token) >= min_length_token]\n\n# def text_cleaning(text):\n#     tokens = tokenize_text(text)\n#     return ' '.join(tokens)\n\n# tqdm.pandas()\n# train_data['text'] = train_data['text'].progress_apply(text_cleaning)\n# test_data['text'] = test_data['text'].progress_apply(text_cleaning)\n\n\nru_stopwords = stopwords.words('russian')\ndigits = [str(i) for i in range(10)]\n\nTOKEN_RE = re.compile(r'[а-яё!.,?%]+')\nlemmatizer = pymorphy2.MorphAnalyzer()\n\ndef is_valid_word(word):\n    if not word[0].isdigit() and word not in ru_stopwords:\n        parsed_word = lemmatizer.normal_forms(word)[0]\n        return parsed_word\n    return False\n\ndef text_cleaning(text):\n    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s.,!?]', '', text)\n    text = re.sub(r'\\s+', ' ', text)\n    text = text.strip()\n    words = text.split()\n    cleaned_words = [word for word in words[:512] if is_valid_word(word) and len(word) < 15]\n    cleaned_text = ' '.join(cleaned_words)\n    return cleaned_text\n\ntqdm.pandas()\ntrain_data['text'] = train_data['text'].progress_apply(text_cleaning)\ntest_data['text'] = test_data['text'].progress_apply(text_cleaning)\n\ntrain_data[\"num_words\"] = train_data[\"text\"].apply(\n    lambda x: len(str(x).split()))\ntest_data[\"num_words\"] = test_data[\"text\"].apply(\n    lambda x: len(str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:19:43.596959Z","iopub.execute_input":"2023-11-05T06:19:43.597285Z","iopub.status.idle":"2023-11-05T06:20:01.348683Z","shell.execute_reply.started":"2023-11-05T06:19:43.597246Z","shell.execute_reply":"2023-11-05T06:20:01.342341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data.to_csv(\"cleaned_train.csv\", index=False)\n# test_data.to_csv(\"cleaned_test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.34945Z","iopub.status.idle":"2023-11-05T06:20:01.349858Z","shell.execute_reply.started":"2023-11-05T06:20:01.34967Z","shell.execute_reply":"2023-11-05T06:20:01.349691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# del zero\ntrain_data = train_data[train_data['num_words'] != 0]\ntest_data = test_data[test_data['num_words'] != 0]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.351384Z","iopub.status.idle":"2023-11-05T06:20:01.351919Z","shell.execute_reply.started":"2023-11-05T06:20:01.35166Z","shell.execute_reply":"2023-11-05T06:20:01.351687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef remove_infrequent_words(dataset, min_count=3):\n    word_counter = Counter()\n    for text in dataset:\n        words = text.split()\n        word_counter.update(words)\n    infrequent_words = [word for word, count in word_counter.items() if count < min_count]\n    def remove_infrequent(text):\n        words = text.split()\n        cleaned_words = [word for word in words if word not in infrequent_words]\n        cleaned_text = ' '.join(cleaned_words)\n        return cleaned_text\n    cleaned_dataset = [remove_infrequent(text) for text in tqdm(dataset, desc=\"Cleaning text\")]\n\n    return cleaned_dataset\n\ncleaned_train = remove_infrequent_words(train_data['text'].tolist())\ncleaned_test = remove_infrequent_words(test_data['text'].tolist())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.353418Z","iopub.status.idle":"2023-11-05T06:20:01.353951Z","shell.execute_reply.started":"2023-11-05T06:20:01.353696Z","shell.execute_reply":"2023-11-05T06:20:01.353721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['cleaned_text'] = cleaned_train\ntest_data['cleaned_text'] = cleaned_test\ntrain_data.to_csv(\"cleaned_train.csv\", index=False)\ntest_data.to_csv(\"cleaned_test.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.356018Z","iopub.status.idle":"2023-11-05T06:20:01.356496Z","shell.execute_reply.started":"2023-11-05T06:20:01.356254Z","shell.execute_reply":"2023-11-05T06:20:01.356278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New data","metadata":{}},{"cell_type":"code","source":"PATH = \"/kaggle/input/cleaned-text\"\ntrain_data = pd.read_csv(os.path.join(PATH, \"cleaned_train (1).csv\"))\ntest_data = pd.read_csv(os.path.join(PATH, \"cleaned_test (1).csv\"))\n# del zero\ntrain_data = train_data[train_data['num_words'] != 0]\ntest_data = test_data[test_data['num_words'] != 0]\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.357774Z","iopub.status.idle":"2023-11-05T06:20:01.358121Z","shell.execute_reply.started":"2023-11-05T06:20:01.357938Z","shell.execute_reply":"2023-11-05T06:20:01.357953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# replace nan\n\ndef replace_nan_with_text(row):\n    if pd.isna(row['cleaned_text']):\n        return row['text']\n    return row['cleaned_text']\n\ntrain_data['cleaned_text'] = train_data.progress_apply(replace_nan_with_text, axis=1)\ntest_data['cleaned_text'] = test_data.progress_apply(replace_nan_with_text, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.359476Z","iopub.status.idle":"2023-11-05T06:20:01.359837Z","shell.execute_reply.started":"2023-11-05T06:20:01.359672Z","shell.execute_reply":"2023-11-05T06:20:01.359689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def truncate_text(text, max_words=512):\n    words = text.split()\n    if len(words) > max_words:\n        truncated_text = ' '.join(words[:max_words])\n    else:\n        truncated_text = text\n    return truncated_text\n\ntqdm.pandas()\ntrain_data['cleaned_text'] = train_data['cleaned_text'].progress_apply(truncate_text)\ntest_data['cleaned_text'] = test_data['cleaned_text'].progress_apply(truncate_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.361828Z","iopub.status.idle":"2023-11-05T06:20:01.362175Z","shell.execute_reply.started":"2023-11-05T06:20:01.362007Z","shell.execute_reply":"2023-11-05T06:20:01.362024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# идея суммирования текста в более короткий текст\n\nmodel_name = \"IlyaGusev/mbart_ru_sum_gazeta\"\ntokenizer = MBartTokenizer.from_pretrained(model_name)\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\n\ndef summary_rows(article_text):\n    input_ids = tokenizer(\n        [article_text],\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True,\n        return_tensors=\"pt\",\n    )[\"input_ids\"]\n\n    output_ids = model.generate(\n        input_ids=input_ids,\n        no_repeat_ngram_size=4\n    )[0]\n\n    summary = tokenizer.decode(output_ids, skip_special_tokens=True)\n    return summary\n\ndef text_summary(text):\n    if isinstance(text, str) and text.strip() and len(str(text).split()) > 150:\n        return summary_rows(text)\n    else:\n        return text\n    \n\ntrain_data['summary'] = train_data['cleaned_text'].progress_apply(text_summary)\ntest_data['summary'] = test_data['cleaned_text'].progress_apply(text_summary)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.363174Z","iopub.status.idle":"2023-11-05T06:20:01.363491Z","shell.execute_reply.started":"2023-11-05T06:20:01.363333Z","shell.execute_reply":"2023-11-05T06:20:01.363348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.364852Z","iopub.status.idle":"2023-11-05T06:20:01.365176Z","shell.execute_reply.started":"2023-11-05T06:20:01.36501Z","shell.execute_reply":"2023-11-05T06:20:01.365025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\"apanc/russian-sensitive-topics\")\ntokenizer = AutoTokenizer.from_pretrained(\"apanc/russian-sensitive-topics\")\ntokenizer.padding = True\ntokenizer.truncation = True\ntokenizer.max_length = 512\npipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=torch.device(\"cuda:0\"))\n\ndef make_pipe(text):\n    return pipe(text, return_all_scores=True)\n\ntqdm.pandas()\ntrain_data['theme_labels'] = train_data['summary'].progress_apply(make_pipe)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.366207Z","iopub.status.idle":"2023-11-05T06:20:01.366526Z","shell.execute_reply.started":"2023-11-05T06:20:01.366361Z","shell.execute_reply":"2023-11-05T06:20:01.366376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_label_probs(row):\n    label_probs = [label['score'] for label in row[0]]\n    return label_probs\n\ntrain_data['label_probs'] = train_data['theme_labels'].apply(extract_label_probs)\n\ntrain_data = pd.concat([train_data, train_data['label_probs'].apply(pd.Series).add_prefix('LABEL_')], axis=1)\n\ndel train_data['label_probs']\ndel train_data['theme_labels']","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.368203Z","iopub.status.idle":"2023-11-05T06:20:01.36852Z","shell.execute_reply.started":"2023-11-05T06:20:01.368364Z","shell.execute_reply":"2023-11-05T06:20:01.368379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature data\ntrain_data.to_csv(\"feature_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.369834Z","iopub.status.idle":"2023-11-05T06:20:01.370157Z","shell.execute_reply.started":"2023-11-05T06:20:01.369999Z","shell.execute_reply":"2023-11-05T06:20:01.370014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # добавление переменных о чувствах\n# from transformers import BertTokenizer, BertForSequenceClassification\n# model_name = 'Skoltech/russian-sensitive-topics'\n# tokenizer = BertTokenizer.from_pretrained(model_name)\n# model = BertForSequenceClassification.from_pretrained(model_name);\n\n# tokenized = tokenizer.batch_encode_plus(train_data[train_data[\"num_words\"] > 80]['text'][370],\n#                                         max_length = 512,\n#                                         pad_to_max_length=True,\n#                                         truncation=True,\n#                                         return_token_type_ids=False)\n\n# tokens_ids,mask = torch.tensor(tokenized['input_ids']),torch.tensor(tokenized['attention_mask']) \n\n# with torch.no_grad():\n#     model_output = model(tokens_ids,mask)\n\n# def adjust_multilabel(y, is_pred = False):\n#     y_adjusted = []\n#     for y_c in y:\n#         y_test_curr = [0]*19\n#         index = str(int(np.argmax(y_c)))\n#         y_c = target_vaiables_id2topic_dict[index]\n#     return y_c\n\n# model_output","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.371813Z","iopub.status.idle":"2023-11-05T06:20:01.372271Z","shell.execute_reply.started":"2023-11-05T06:20:01.372035Z","shell.execute_reply":"2023-11-05T06:20:01.372058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# тональность текста\npipe = pipeline(model=\"seara/rubert-tiny2-russian-sentiment\", device=torch.device(\"cuda:0\"))\n\ntqdm.pandas()\ntrain_data['mood'] = train_data['summary'].progress_apply(make_pipe)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.373498Z","iopub.status.idle":"2023-11-05T06:20:01.373983Z","shell.execute_reply.started":"2023-11-05T06:20:01.373749Z","shell.execute_reply":"2023-11-05T06:20:01.373772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['label_probs'] = train_data['mood'].apply(extract_label_probs)\n\ntrain_data = pd.concat([train_data, train_data['label_probs'].progress_apply(pd.Series).add_prefix('MOOD_')], axis=1)\n\ndel train_data['label_probs']\ndel train_data['mood']","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.375418Z","iopub.status.idle":"2023-11-05T06:20:01.375899Z","shell.execute_reply.started":"2023-11-05T06:20:01.375661Z","shell.execute_reply":"2023-11-05T06:20:01.375683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature data\ntrain_data.to_csv(\"feature_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.377384Z","iopub.status.idle":"2023-11-05T06:20:01.377745Z","shell.execute_reply.started":"2023-11-05T06:20:01.377566Z","shell.execute_reply":"2023-11-05T06:20:01.377586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# токичность\n\n# tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n# model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n# batch = tokenizer.encode(train_data[train_data[\"num_words\"] > 80]['text'][48421], return_tensors='pt')\n# model(batch)\n\npipe = pipeline(model=\"SkolkovoInstitute/russian_toxicity_classifier\", device=torch.device(\"cuda:0\"))\n\ntqdm.pandas()\ntrain_data['toxic'] = train_data['summary'].progress_apply(make_pipe)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.37938Z","iopub.status.idle":"2023-11-05T06:20:01.379758Z","shell.execute_reply.started":"2023-11-05T06:20:01.37958Z","shell.execute_reply":"2023-11-05T06:20:01.379599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['label_probs'] = train_data['toxic'].apply(extract_label_probs)\n\ntrain_data = pd.concat([train_data, train_data['label_probs'].progress_apply(pd.Series).add_prefix('TOXIC_')], axis=1)\n\ndel train_data['label_probs']\ndel train_data['toxic']","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.380938Z","iopub.status.idle":"2023-11-05T06:20:01.381261Z","shell.execute_reply.started":"2023-11-05T06:20:01.381104Z","shell.execute_reply":"2023-11-05T06:20:01.381119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# эмоции\n\nLABELS = ['neutral', 'happiness', 'sadness', 'enthusiasm', 'fear', 'anger', 'disgust']\ntokenizer = AutoTokenizer.from_pretrained('Aniemore/rubert-tiny2-russian-emotion-detection')\nmodel = BertForSequenceClassification.from_pretrained('Aniemore/rubert-tiny2-russian-emotion-detection')\n\n@torch.no_grad()\ndef predict_emotion(text: str) -> str:\n    \"\"\"\n        We take the input text, tokenize it, pass it through the model, and then return the predicted label\n        :param text: The text to be classified\n        :type text: str\n        :return: The predicted emotion\n    \"\"\"\n    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n    outputs = model(**inputs)\n    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n    predicted = torch.argmax(predicted, dim=1).numpy()\n        \n    return LABELS[predicted[0]]\n\n@torch.no_grad()    \ndef predict_emotions(text: str) -> list:\n    \"\"\"\n        It takes a string of text, tokenizes it, feeds it to the model, and returns a dictionary of emotions and their\n        probabilities\n        :param text: The text you want to classify\n        :type text: str\n        :return: A dictionary of emotions and their probabilities.\n    \"\"\"\n    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n    outputs = model(**inputs)\n    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n    emotions_list = {}\n    for i in range(len(predicted.numpy()[0].tolist())):\n        emotions_list[LABELS[i]] = predicted.numpy()[0].tolist()[i]\n    return emotions_list\n\ntrain_data['toxic'] = train_data['summary'].progress_apply(predict_emotions)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.382385Z","iopub.status.idle":"2023-11-05T06:20:01.382747Z","shell.execute_reply.started":"2023-11-05T06:20:01.382569Z","shell.execute_reply":"2023-11-05T06:20:01.382587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['toxic'][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.384155Z","iopub.status.idle":"2023-11-05T06:20:01.384632Z","shell.execute_reply.started":"2023-11-05T06:20:01.38437Z","shell.execute_reply":"2023-11-05T06:20:01.384393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_label_probs(row):\n    label_probs = [row.get(label, 0.0) for label in LABELS]\n    return label_probs\n\ntrain_data['label_probs'] = train_data['toxic'].apply(extract_label_probs)\n\ntrain_data = pd.concat([train_data, train_data['label_probs'].progress_apply(pd.Series).add_prefix('EMOTION_')], axis=1)\n\ndel train_data['label_probs']\ndel train_data['toxic']","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.385764Z","iopub.status.idle":"2023-11-05T06:20:01.386206Z","shell.execute_reply.started":"2023-11-05T06:20:01.385976Z","shell.execute_reply":"2023-11-05T06:20:01.385998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# feature data\ntrain_data.to_csv(\"feature_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.387611Z","iopub.status.idle":"2023-11-05T06:20:01.38807Z","shell.execute_reply.started":"2023-11-05T06:20:01.387835Z","shell.execute_reply":"2023-11-05T06:20:01.387857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ______________________________________","metadata":{}},{"cell_type":"code","source":"PATH = \"/kaggle/input/ods-huawei/\"\ntrain_data = pd.read_csv(os.path.join(PATH, \"feature_train.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:04:59.971803Z","iopub.execute_input":"2023-11-05T11:04:59.972205Z","iopub.status.idle":"2023-11-05T11:05:12.224832Z","shell.execute_reply.started":"2023-11-05T11:04:59.972173Z","shell.execute_reply":"2023-11-05T11:05:12.224023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[\"num_words_sum\"] = train_data[\"summary\"].apply(\n    lambda x: len(str(x).split()))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:05:12.226647Z","iopub.execute_input":"2023-11-05T11:05:12.226929Z","iopub.status.idle":"2023-11-05T11:05:12.327256Z","shell.execute_reply.started":"2023-11-05T11:05:12.226904Z","shell.execute_reply":"2023-11-05T11:05:12.326498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(train_data[\"num_words_sum\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:05:12.328224Z","iopub.execute_input":"2023-11-05T11:05:12.328469Z","iopub.status.idle":"2023-11-05T11:05:12.340259Z","shell.execute_reply.started":"2023-11-05T11:05:12.328447Z","shell.execute_reply":"2023-11-05T11:05:12.339361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! textblob - обработка текста, генерация фич https://textblob.readthedocs.io/en/dev/quickstart.html - ничего интересного\n# ! еще одна библиотека для классификации текстов https://small-text.readthedocs.io/en/latest/ не подходит? для малкеньких текстов\n# ! полярность слов https://polyglot.readthedocs.io/en/latest/ - тоже? что уже получил из предобученных моделей\n# ! обработка фич https://github.com/jbesomi/texthero - плохо поддерживается\n# фичегенерация https://github.com/neomatrix369/nlp_profiler#Notebooks\n# классификация на других предобученных моделях, перечисленных у Алерона https://github.com/a-milenkin/Competitive_Data_Science/blob/main/notebooks/9.2.1%20-%20Text_Embeddings.ipynb\n# использовать эти ноутбуки для классификации https://github.com/e0xextazy/vkcup2022-first-stage/blob/main/inference.ipynb","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.39724Z","iopub.status.idle":"2023-11-05T06:20:01.397729Z","shell.execute_reply.started":"2023-11-05T06:20:01.39746Z","shell.execute_reply":"2023-11-05T06:20:01.397482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Small Text Classifer","metadata":{}},{"cell_type":"code","source":"# !pip install small_text > installer_log.txt","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:22:38.466228Z","iopub.execute_input":"2023-11-05T09:22:38.466604Z","iopub.status.idle":"2023-11-05T09:22:50.504622Z","shell.execute_reply.started":"2023-11-05T09:22:38.466572Z","shell.execute_reply":"2023-11-05T09:22:50.503517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoTokenizer\n# from small_text import TransformersDataset\n\n# num_classes = np.unique(train_data['rate']).shape[0]\n# target_labels = np.arange(num_classes)\n\n# train_split, val_split = train_test_split(train_data, test_size=0.15, random_state=42, \n#                                           shuffle = True, stratify=train_data['rate'])\n# train_split = train_split.reset_index()\n# val_split = val_split.reset_index()\n\n# transformer_model_name = 'ai-forever/ruBert-base'\n\n# tokenizer = AutoTokenizer.from_pretrained(\n#     transformer_model_name\n# )\n\n# train = TransformersDataset.from_arrays(train_split['text'],\n#                                         train_split['rate'],\n#                                         tokenizer,\n#                                         max_length=150,\n#                                         target_labels=target_labels)\n# test = TransformersDataset.from_arrays(val_split['text'],\n#                                        val_split['rate'],\n#                                        tokenizer,\n#                                        max_length=150,\n#                                        target_labels=target_labels)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:23:45.734607Z","iopub.execute_input":"2023-11-05T09:23:45.735362Z","iopub.status.idle":"2023-11-05T09:24:08.487498Z","shell.execute_reply.started":"2023-11-05T09:23:45.735328Z","shell.execute_reply":"2023-11-05T09:24:08.486674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Active Learning","metadata":{}},{"cell_type":"code","source":"\n# sentence_transformer_model_name = 'cointegrated/rubert-tiny2'\n\n# from small_text import (\n#     PoolBasedActiveLearner,\n#     PredictionEntropy,\n#     TransformerBasedClassificationFactory,\n#     TransformerModelArguments,\n#     random_initialization_balanced\n# )\n\n\n# def initialize_active_learner(active_learner, y_train):\n\n#     indices_initial = random_initialization_balanced(y_train, n_samples=100)\n#     active_learner.initialize_data(indices_initial, y_train[indices_initial])\n\n#     return indices_initial\n\n# transformer_model = TransformerModelArguments(transformer_model_name)\n# clf_factory = TransformerBasedClassificationFactory(transformer_model, \n#                                                     num_classes, \n#                                                     kwargs=dict({'device': 'cuda', \n#                                                                  'mini_batch_size': 32,\n#                                                                  'class_weight': 'balanced'\n#                                                                 }))\n# query_strategy = PredictionEntropy()\n# active_learner = PoolBasedActiveLearner(clf_factory, query_strategy, train)\n# indices_labeled = initialize_active_learner(active_learner, train.y)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:30:06.545975Z","iopub.execute_input":"2023-11-05T09:30:06.546888Z","iopub.status.idle":"2023-11-05T09:31:47.488678Z","shell.execute_reply.started":"2023-11-05T09:30:06.546853Z","shell.execute_reply":"2023-11-05T09:31:47.487536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Active Learning Loop","metadata":{}},{"cell_type":"code","source":"# from sklearn.metrics import accuracy_score\n# from small_text import KappaAverage\n\n\n# num_queries = 20\n# stopping_criterion = KappaAverage(num_classes, kappa=0.99)\n\n\n# def evaluate(active_learner, train, test):\n#     y_pred = active_learner.classifier.predict(train)\n#     y_pred_test = active_learner.classifier.predict(test)\n#     train_acc = accuracy_score(y_pred, train.y)\n\n#     print('Train accuracy: {:.2f}'.format(train_acc))\n#     print('Test accuracy: {:.2f}'.format(accuracy_score(y_pred_test, test.y)))\n    \n#     return train_acc\n\n\n# results = []\n# stopping_history = []\n\n# results.append(evaluate(active_learner, train[indices_labeled], test))\n# stopping_history.append(stopping_criterion.stop(predictions=active_learner.classifier.predict(train)))\n\n\n# for i in range(num_queries):\n#     indices_queried = active_learner.query(num_samples=50)\n#     y = train.y[indices_queried]\n#     active_learner.update(y)\n#     indices_labeled = np.concatenate([indices_queried, indices_labeled])\n    \n#     print('---------------')\n#     print(f'Iteration #{i} ({len(indices_labeled)} samples)')\n#     results.append(evaluate(active_learner, train[indices_labeled], test))\n    \n#     stopping_criterion_response = stopping_criterion.stop(predictions=active_learner.classifier.predict(train))\n#     print(f'Stop: {stopping_criterion_response}')\n#     stopping_history.append(stopping_criterion_response)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T09:31:47.490571Z","iopub.execute_input":"2023-11-05T09:31:47.490909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %matplotlib inline\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n\n# fig = plt.figure(figsize=(12, 8))\n# ax = plt.axes()\n\n# data = np.vstack((np.arange(num_queries+1), np.array(results)))\n# sns.lineplot(x=0, y=1, data=data)\n\n# plt.xlabel('number of queries', labelpad=15)\n# plt.ylabel('train accuracy', labelpad=25)\n\n# earliest_stopping_response = np.amin([i for i, _ in enumerate(stopping_history) if stopping_history[i] is True])\n# plt.axvline(x=earliest_stopping_response, ymin=0, ymax=1, color='purple', ls='--')\n\n# sns.despine()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.404011Z","iopub.status.idle":"2023-11-05T06:20:01.40447Z","shell.execute_reply.started":"2023-11-05T06:20:01.404234Z","shell.execute_reply":"2023-11-05T06:20:01.404257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data = TransformersDataset.from_arrays(train['summary'],\n#                                         train['rate'],\n#                                         tokenizer,\n#                                         max_length=150,\n#                                         target_labels=target_labels)\n# preds = active_learner.classifier.predict(data)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.405827Z","iopub.status.idle":"2023-11-05T06:20:01.406169Z","shell.execute_reply.started":"2023-11-05T06:20:01.405998Z","shell.execute_reply":"2023-11-05T06:20:01.406014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NLP profiler","metadata":{}},{"cell_type":"code","source":"# !pip uninstall typing      # this can cause issues on Kaggle hence removing it helps\n# !pip install -U nlp_profiler","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.418659Z","iopub.status.idle":"2023-11-05T06:20:01.418996Z","shell.execute_reply.started":"2023-11-05T06:20:01.41883Z","shell.execute_reply":"2023-11-05T06:20:01.418846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"profiled_text_dataframe = apply_text_profiling(train_data, 'text')","metadata":{"execution":{"iopub.status.busy":"2023-11-05T06:20:01.420107Z","iopub.status.idle":"2023-11-05T06:20:01.420444Z","shell.execute_reply.started":"2023-11-05T06:20:01.420278Z","shell.execute_reply":"2023-11-05T06:20:01.420294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SpaCy","metadata":{}},{"cell_type":"code","source":"# !pip install -U pip setuptools wheel > installer_log.text\n# !pip install spacy > installer_log.text","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:11:34.542102Z","iopub.execute_input":"2023-11-05T11:11:34.543035Z","iopub.status.idle":"2023-11-05T11:12:11.123043Z","shell.execute_reply.started":"2023-11-05T11:11:34.542987Z","shell.execute_reply":"2023-11-05T11:12:11.121798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stopwords = stopwords.words('russian')\nprint (stopwords)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:13:09.570145Z","iopub.execute_input":"2023-11-05T11:13:09.570511Z","iopub.status.idle":"2023-11-05T11:13:09.581996Z","shell.execute_reply.started":"2023-11-05T11:13:09.570475Z","shell.execute_reply":"2023-11-05T11:13:09.581149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tqdm.pandas()\n## Number of unique words in the text ##\ntrain_data[\"num_unique_words\"] = train_data[\"text\"].progress_apply(lambda x: len(set(str(x).split())))\n# test_data[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\n## Number of stopwords in the text ##\ntrain_data[\"num_stopwords\"] = train_data[\"text\"].progress_apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords]))\n# test_data[\"num_stopwords\"] = test_data[\"text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in stopwords]))","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:15:08.42389Z","iopub.execute_input":"2023-11-05T11:15:08.424813Z","iopub.status.idle":"2023-11-05T11:15:10.158024Z","shell.execute_reply.started":"2023-11-05T11:15:08.424769Z","shell.execute_reply":"2023-11-05T11:15:10.15712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features of POS\\o\n\nclass TextPOSAnalysis:\n    def __init__(self):\n        self.nlp_ru = ru_core_news_md.load()\n        self.df_pos = self.load_pos_table()\n        self.m = Mystem()\n\n    def load_pos_table(self):\n        table = \"\"\"\n        A       ADJ\n        ADV     ADV\n        ADVPRO  ADV\n        ANUM    ADJ\n        APRO    DET\n        COM     ADJ\n        CONJ    SCONJ\n        INTJ    INTJ\n        NONLEX  X\n        NUM     NUM\n        PART    PART\n        PR      ADP\n        S       NOUN\n        SPRO    PRON\n        UNKN    X\n        V       VERB\n        \"\"\"\n        table_file = io.StringIO(table)\n        df = pd.read_csv(table_file, sep=\"\\s+\", header=None, names=[\"token\", \"universal_pos\"])\n        return df\n\n    def get_universal_tag(self, word):\n        processed = self.m.analyze(word)[0]\n        lemma = processed[\"analysis\"][0][\"lex\"].lower().strip()\n        pos = processed[\"analysis\"][0][\"gr\"].split(',')[0]\n        pos = pos.split('=')[0].strip()\n        tagged = lemma + '_' + pos\n        return tagged\n\n    def add_tag(self, word):\n        word = self.get_universal_tag(word)\n        tag = word.split('_')[1]\n        tag = self.df_pos[self.df_pos['token'] == tag]['universal_pos'].values[0] if tag in self.df_pos['token'].values else tag\n        word = word.split('_')[0] + '_' + tag\n        return word\n\n    def analyze_text(self, text):\n        doc = self.nlp_ru(text)\n        num_adj = len([tok for tok in doc if tok.pos_ == 'ADJ'])\n        num_adv = len([tok for tok in doc if tok.pos_ == 'ADV'])\n        num_noun = len([tok for tok in doc if tok.pos_ == 'NOUN'])\n        num_verb = len([tok for tok in doc if tok.pos_ == 'VERB'])\n        return num_adj, num_noun, num_verb, num_adv\n\n    def analyze_texts(self, texts):\n        results = []\n        for text in texts:\n            results.append(self.analyze_text(text))\n        return pd.DataFrame(results, columns=[\"Num_ADJ\", \"Num_ADV\", \"Num_NOUN\", \"Num_VERB\"])\n\n\ntext_POS = TextPOSAnalysis()\nPOS_results = text_POS.analyze_texts(train_data['text'])\ntrain_data = pd.concat([train_data, POS_results], axis=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T11:22:35.206268Z","iopub.execute_input":"2023-11-05T11:22:35.206637Z","iopub.status.idle":"2023-11-05T11:33:38.444881Z","shell.execute_reply.started":"2023-11-05T11:22:35.206607Z","shell.execute_reply":"2023-11-05T11:33:38.443825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.iloc[:, 410:417].to_csv(\"add_feature_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:28:11.048505Z","iopub.execute_input":"2023-11-05T12:28:11.049221Z","iopub.status.idle":"2023-11-05T12:28:11.191689Z","shell.execute_reply.started":"2023-11-05T12:28:11.049185Z","shell.execute_reply":"2023-11-05T12:28:11.19094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ______________________________________","metadata":{}},{"cell_type":"code","source":"PATH = \"/kaggle/input/ods-huawei/\"\ntrain_data = pd.read_csv(os.path.join(PATH, \"feature_train.csv\"))\nadd_feature = pd.read_csv(os.path.join(PATH, \"add_feature_train.csv\"))\nprofiler_add_feature = pd.read_csv(os.path.join(PATH, \"feature_profiler_train.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T03:16:37.699242Z","iopub.execute_input":"2023-11-06T03:16:37.699742Z","iopub.status.idle":"2023-11-06T03:16:53.47044Z","shell.execute_reply.started":"2023-11-06T03:16:37.699704Z","shell.execute_reply":"2023-11-06T03:16:53.46944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.concat([train_data, add_feature, profiler_add_feature], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T03:20:22.103711Z","iopub.execute_input":"2023-11-06T03:20:22.104203Z","iopub.status.idle":"2023-11-06T03:20:22.110479Z","shell.execute_reply.started":"2023-11-06T03:20:22.104169Z","shell.execute_reply":"2023-11-06T03:20:22.109024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"# Shap","metadata":{}},{"cell_type":"code","source":"train_split, val_split = train_test_split(train_data, test_size=0.15, random_state=42, \n                                          shuffle = True, stratify=train_data['rate'])\ntrain_X = train_split.iloc[:, 5:441] \ntrain_Y = train_split['rate']\n\nval_X = val_split.iloc[:, 5:441] \nval_Y = val_split['rate']\n\ndel_columns = ['text', 'sentiment_polarity',\n       'sentiment_polarity_summarised',\n       'sentiment_subjectivity', 'sentiment_subjectivity_summarised',\n       'spelling_quality',\n       'spelling_quality_summarised']\n\ntrain_X = train_X.drop(columns = del_columns)\nval_X = val_X.drop(columns = del_columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:19:18.744966Z","iopub.execute_input":"2023-11-06T05:19:18.745433Z","iopub.status.idle":"2023-11-06T05:19:19.220403Z","shell.execute_reply.started":"2023-11-06T05:19:18.745398Z","shell.execute_reply":"2023-11-06T05:19:19.219089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = CatBoostClassifier(random_seed=9,\n                        thread_count=-1,\n                        use_best_model=True,\n                        bootstrap_type='Bernoulli')\n\nclf.fit(train_X, train_Y,\n        eval_set=(val_X, val_Y),\n        verbose=100,\n        plot=True,\n        early_stopping_rounds=1000)\n\nprint(clf.get_best_score())","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:20:51.492901Z","iopub.execute_input":"2023-11-06T05:20:51.493342Z","iopub.status.idle":"2023-11-06T05:27:51.8815Z","shell.execute_reply.started":"2023-11-06T05:20:51.493305Z","shell.execute_reply":"2023-11-06T05:27:51.880034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fi = clf.get_feature_importance(prettified=True)[:100]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:28:12.256188Z","iopub.execute_input":"2023-11-06T05:28:12.256685Z","iopub.status.idle":"2023-11-06T05:28:12.272037Z","shell.execute_reply.started":"2023-11-06T05:28:12.256646Z","shell.execute_reply":"2023-11-06T05:28:12.270408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explainer = shap.TreeExplainer(clf)\n\n# val_dataset = Pool(data=val_split.iloc[:, 5:417], label=val_split['rate'])\n# shap_values = explainer.shap_values(val_dataset)\n# shap.summary_plot(shap_values, val_split.iloc[:, 5:417], max_display = 50, plot_size = (15, 5))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:28:12.809113Z","iopub.execute_input":"2023-11-06T05:28:12.809603Z","iopub.status.idle":"2023-11-06T05:28:12.816435Z","shell.execute_reply.started":"2023-11-06T05:28:12.809569Z","shell.execute_reply":"2023-11-06T05:28:12.814938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(np.unique(val_split['rate'].values))):\n#     print(f'Class {i}')\n#     shap.summary_plot(shap_values[i], val_split.iloc[:, 5:417], max_display = 50, color_bar=True, plot_size = (15, 5))","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:28:13.437567Z","iopub.execute_input":"2023-11-06T05:28:13.438018Z","iopub.status.idle":"2023-11-06T05:28:13.443404Z","shell.execute_reply.started":"2023-11-06T05:28:13.437982Z","shell.execute_reply":"2023-11-06T05:28:13.44224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_X = train_X[fi['Feature Id'].to_list()]\nval_X = val_X[fi['Feature Id'].to_list()]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:28:19.925097Z","iopub.execute_input":"2023-11-06T05:28:19.925615Z","iopub.status.idle":"2023-11-06T05:28:19.952556Z","shell.execute_reply.started":"2023-11-06T05:28:19.925579Z","shell.execute_reply":"2023-11-06T05:28:19.950896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Рекурсивный feature_selection Catboost","metadata":{}},{"cell_type":"code","source":"summary = clf.select_features(train_X, train_Y, \n                      eval_set=(val_X, val_Y),\n                      features_for_select='0-99',\n                      num_features_to_select=50,\n                      steps=1,\n                      train_final_model=False,\n                      logging_level='Silent')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:28:26.512725Z","iopub.execute_input":"2023-11-06T05:28:26.514226Z","iopub.status.idle":"2023-11-06T05:30:26.454735Z","shell.execute_reply.started":"2023-11-06T05:28:26.514147Z","shell.execute_reply":"2023-11-06T05:30:26.453766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save new_train","metadata":{}},{"cell_type":"code","source":"summary['selected_features_names'].extend(['text', 'summary'])","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:35:28.847678Z","iopub.execute_input":"2023-11-06T05:35:28.848186Z","iopub.status.idle":"2023-11-06T05:35:28.854908Z","shell.execute_reply.started":"2023-11-06T05:35:28.84815Z","shell.execute_reply":"2023-11-06T05:35:28.853585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_train = train_data[summary['selected_features_names']]\nnew_train.to_csv(\"new_train.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T05:35:47.650568Z","iopub.execute_input":"2023-11-06T05:35:47.652816Z","iopub.status.idle":"2023-11-06T05:35:53.891881Z","shell.execute_reply.started":"2023-11-06T05:35:47.652735Z","shell.execute_reply":"2023-11-06T05:35:53.890133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}