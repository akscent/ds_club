{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"papermill":{"default_parameters":{},"duration":91.411499,"end_time":"2022-10-09T03:36:04.617837","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2022-10-09T03:34:33.206338","version":"2.3.4"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":26266,"databundleVersionId":2030504,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom catboost import CatBoostClassifier\nfrom matplotlib import pyplot as plt\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom pprint import pprint\nfrom warnings import filterwarnings\n\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\n\nfilterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\nfilterwarnings(\"ignore\", category=FutureWarning)\nfilterwarnings(\"ignore\", category=Warning)\nfilterwarnings(\"ignore\", category=DeprecationWarning)\n\n!pip install openfe pyod combo > installer.text\n!pip install --upgrade openfe > installer.text\n","metadata":{"id":"6d5debb1","papermill":{"duration":1.93347,"end_time":"2022-10-09T03:34:44.544551","exception":false,"start_time":"2022-10-09T03:34:42.611081","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-22T17:18:52.638467Z","iopub.execute_input":"2023-11-22T17:18:52.639191Z","iopub.status.idle":"2023-11-22T17:18:52.650848Z","shell.execute_reply.started":"2023-11-22T17:18:52.639091Z","shell.execute_reply":"2023-11-22T17:18:52.648971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{"id":"891fe076","papermill":{"duration":0.015378,"end_time":"2022-10-09T03:34:44.577856","exception":false,"start_time":"2022-10-09T03:34:44.562478","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = \"/kaggle/input/advanced-dls-spring-2021/\"\ndata = pd.read_csv(INPUT_DIR + \"train.csv\")\nX_test = pd.read_csv(INPUT_DIR + \"test.csv\")\n\nnum_cols = [\n    \"ClientPeriod\",\n    \"MonthlySpending\",\n    \"TotalSpent\",\n]\n\ncat_cols = [\n    \"Sex\",\n    \"IsSeniorCitizen\",\n    \"HasPartner\",\n    \"HasChild\",\n    \"HasPhoneService\",\n    \"HasMultiplePhoneNumbers\",\n    \"HasInternetService\",\n    \"HasOnlineSecurityService\",\n    \"HasOnlineBackup\",\n    \"HasDeviceProtection\",\n    \"HasTechSupportAccess\",\n    \"HasOnlineTV\",\n    \"HasMovieSubscription\",\n    \"HasContractPhone\",\n    \"IsBillingPaperless\",\n    \"PaymentMethod\",\n]\n\ntarget = 'Churn'","metadata":{"id":"3fb26779","papermill":{"duration":0.086748,"end_time":"2022-10-09T03:34:44.680461","exception":false,"start_time":"2022-10-09T03:34:44.593713","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-22T14:17:43.877776Z","iopub.execute_input":"2023-11-22T14:17:43.878188Z","iopub.status.idle":"2023-11-22T14:17:43.95468Z","shell.execute_reply.started":"2023-11-22T14:17:43.878141Z","shell.execute_reply":"2023-11-22T14:17:43.953643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Choose model","metadata":{}},{"cell_type":"markdown","source":"* Используем choos model из предыдущей работы - расширенный - https://www.kaggle.com/code/akscent/choice-of-boosting\n* Отличный ноутбук с оценкой и ансамблированием моделей - https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n* Далее оптимизаторы гиперпараметр**ов - https://www.kaggle.com/code/akscent/ods-boosting\n* Далее стекинг - https://www.kaggle.com/code/akscent/ods-boosting ; https://alexanderdyakonov.wordpress.com/2017/03/10/c%D1%82%D0%B5%D0%BA%D0%B8%D0%BD%D0%B3-stacking-%D0%B8-%D0%B1%D0%BB%D0%B5%D0%BD%D0%B4%D0%B8%D0%BD%D0%B3-blending/ ; https://github.com/a-milenkin/Competitive_Data_Science/blob/main/notebooks/6.3%20-%20Automatic%20Stacking.ipynb","metadata":{}},{"cell_type":"code","source":"#Common Model Algorithms\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n#Visualization\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.tools.plotting import scatter_matrix\n\n#Configure Visualization Defaults\n#%matplotlib inline = show plots in Jupyter Notebook browser\n%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Machine Learning Algorithms (MLA)\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier() \n    \n    #lgbm\n    \n    #catboost\n    ]\n\ndef evaluate_ml_algorithms(MLA, data, data_x, target, cv_splits=10, test_size=0.3, train_size=0.6, random_state=0):\n    MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n    MLA_compare = pd.DataFrame(columns=MLA_columns)\n    \n    MLA_predict = data[target]\n    \n    cv_split = model_selection.ShuffleSplit(n_splits=cv_splits, test_size=test_size, train_size=train_size, random_state=random_state)\n\n    row_index = 0\n    for alg in MLA:\n        MLA_name = alg.__class__.__name__\n        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n        \n        cv_results = model_selection.cross_validate(alg, data[data_x], data[target], cv=cv_split)\n\n        MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n        MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n        MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n        MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std() * 3\n        alg.fit(data[data_x], data[target])\n        MLA_predict[MLA_name] = alg.predict(data[data_x])\n        \n        row_index += 1\n\n    MLA_compare.sort_values(by=['MLA Test Accuracy Mean'], ascending=False, inplace=True)\n    \n    correlation_heatmap(MLA_predict)\n    \n    return MLA_compare\n\nresult = evaluate_ml_algorithms(MLA, data, data_x, target)\n\nsns.barplot(x='MLA Test Accuracy Mean', y = 'MLA Name', data = result)\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}